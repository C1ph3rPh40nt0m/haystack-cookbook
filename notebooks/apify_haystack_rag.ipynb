{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# RAG: Extract and use website content for question answering with Apify-Haystack integration\n",
        "\n",
        "Author: Jiri Spilka ([Apify](https://apify.com/jiri.spilka))\n",
        "\n",
        "In this tutorial, we'll use the [apify-haystack](https://github.com/apify/apify-haystack/tree/main) integration to call [Website Content Crawler](https://apify.com/apify/website-content-crawler) and crawl and scrape text content from the [Haystack website](https://haystack.deepset.ai). Then, we'll use the [OpenAIDocumentEmbedder](https://docs.haystack.deepset.ai/docs/openaidocumentembedder) to compute text embeddings and the [InMemoryDocumentStore](https://docs.haystack.deepset.ai/docs/inmemorydocumentstore) to store documents in a temporary in-memory database. The last step will be a retrieval augmented generation pipeline to answer users' questions from the scraped data.\n",
        "\n",
        "\n",
        "## Install dependencies"
      ],
      "metadata": {
        "id": "t1BeKtSo7KzI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install apify-haystack haystack-ai"
      ],
      "metadata": {
        "id": "r5AJeMOE1Cou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up the API keys\n",
        "\n",
        "You need to have an Apify account and obtain [APIFY_API_TOKEN](https://docs.apify.com/platform/integrations/api).\n",
        "\n",
        "You also need an OpenAI account and [OPENAI_API_KEY](https://platform.openai.com/docs/quickstart)\n"
      ],
      "metadata": {
        "id": "h6MmIG9K1HkK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "os.environ[\"APIFY_API_TOKEN\"] = getpass(\"Enter YOUR APIFY_API_TOKEN\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter YOUR OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "yiUTwYzP36Yr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b53b07db-42a9-4109-e322-705a8312da2e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter YOUR APIFY_API_TOKEN··········\n",
            "Enter YOUR OPENAI_API_KEY··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use the Website Content Crawler to scrape data from the haystack documentation\n",
        "\n",
        "Now, let us call the Website Content Crawler using the Haystack component `ApifyDatasetFromActorCall`. First, we need to define parameters for the Website Content Crawler and then what data we need to save into the vector database.\n",
        "\n",
        "The `actor_id` and detailed description of input parameters (variable `run_input`) can be found on the [Website Content Crawler input page](https://apify.com/apify/website-content-crawler/input-schema).\n",
        "\n",
        "For this example, we will define `startUrls` and limit the number of crawled pages to five."
      ],
      "metadata": {
        "id": "HQzAujMc505k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "actor_id = \"apify/website-content-crawler\"\n",
        "run_input = {\n",
        "    \"maxCrawlPages\": 5,  # limit the number of pages to crawl\n",
        "    \"startUrls\": [{\"url\": \"https://haystack.deepset.ai/\"}],\n",
        "}"
      ],
      "metadata": {
        "id": "_AYgcfBx681h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we need to define a dataset mapping function. We need to know the output of the Website Content Crawler. Typically, it is a JSON object that looks like this (truncated for brevity):\n",
        "\n",
        "```\n",
        "[\n",
        "  {\n",
        "    \"url\": \"https://haystack.deepset.ai/\",\n",
        "    \"text\": \"Haystack | Haystack - Multimodal - AI - Architect a next generation AI app around all modalities, not just text ...\"\n",
        "  },\n",
        "  {\n",
        "    \"url\": \"https://haystack.deepset.ai/tutorials/24_building_chat_app\",\n",
        "    \"text\": \"Building a Conversational Chat App ... \"\n",
        "  },\n",
        "]\n",
        "```\n",
        "\n",
        "We will convert this JSON to a Haystack `Document` using the `dataset_mapping_function` as follows:\n"
      ],
      "metadata": {
        "id": "yIODy29t-_JY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack import Document\n",
        "\n",
        "def dataset_mapping_function(dataset_item: dict) -> Document:\n",
        "    return Document(content=dataset_item.get(\"text\"), meta={\"url\": dataset_item.get(\"url\")})"
      ],
      "metadata": {
        "id": "OZ0PAVHI_mhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And the definition of the `ApifyDatasetFromActorCall`:"
      ],
      "metadata": {
        "id": "xtFquWflA5kf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from apify_haystack import ApifyDatasetFromActorCall\n",
        "\n",
        "apify_dataset_loader = ApifyDatasetFromActorCall(\n",
        "    actor_id=actor_id,\n",
        "    run_input=run_input,\n",
        "    dataset_mapping_function=dataset_mapping_function,\n",
        ")"
      ],
      "metadata": {
        "id": "gdN7baGrA_lR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before actually running the Website Content Crawler, we need to define embedding function and document store:"
      ],
      "metadata": {
        "id": "3hG6SvMm_mAB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.components.embedders import OpenAIDocumentEmbedder\n",
        "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
        "\n",
        "document_store = InMemoryDocumentStore()\n",
        "docs_embedder = OpenAIDocumentEmbedder()"
      ],
      "metadata": {
        "id": "zKr0KTfhAQz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After that, we can call the Website Content Crawler and print the scraped data:"
      ],
      "metadata": {
        "id": "GxDNZ7LqAsWV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crawler website and store documents in the document_store\n",
        "# Crawling will take some time (1-2 minutes), you can monitor progress in the https://console.apify.com/actors/runs\n",
        "\n",
        "docs = apify_dataset_loader.run()\n",
        "print(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfaWI6BaAko9",
        "outputId": "ba5e115e-4c9d-42fd-c167-0bf06163d52c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'documents': [Document(id=6c4d570874ff59ed4e06017694bee8a72d766d2ed55c6453fbc9ea91fd2e6bde, content: 'Haystack | Haystack Luma · Delightful Events Start HereAWS Summit Berlin 2023: Building Generative A...', meta: {'url': 'https://haystack.deepset.ai/'}), Document(id=d420692bf66efaa56ebea200a4a63597667bdc254841b99654239edf67737bcb, content: 'Tutorials & Walkthroughs | Haystack\n",
            "Tutorials & Walkthroughs2.0\n",
            "Whether you’re a beginner or an expe...', meta: {'url': 'https://haystack.deepset.ai/tutorials'}), Document(id=5a529a308d271ba76f66a060c0b706b73103406ac8a853c19f20e1594823efe8, content: 'Get Started | Haystack\n",
            "Haystack is an open-source Python framework that helps developers build LLM-p...', meta: {'url': 'https://haystack.deepset.ai/overview/quick-start'}), Document(id=1d126a03ae50586729846d492e9e8aca802d7f281a72a8869ded08ebc5585a36, content: 'What is Haystack? | Haystack\n",
            "Haystack is an open source framework for building production-ready LLM ...', meta: {'url': 'https://haystack.deepset.ai/overview/intro'}), Document(id=4324a62242590d4ecf9b080319607fa1251aa0822bbe2ce6b21047e783999703, content: 'Integrations | Haystack\n",
            "The Haystack ecosystem integrates with many other technologies, such as vect...', meta: {'url': 'https://haystack.deepset.ai/integrations'})]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute the embeddings and store them in the database:"
      ],
      "metadata": {
        "id": "OxIGcmHcClQo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = docs_embedder.run(docs.get(\"documents\"))\n",
        "document_store.write_documents(embeddings[\"documents\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrKAkHLuCp6N",
        "outputId": "a0234fa4-1265-4212-be6a-f844708126e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating embeddings: 100%|██████████| 1/1 [00:00<00:00,  3.29it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retrieval and LLM generative pipeline\n",
        "\n",
        "Once we have the crawled data in the database, we can set up the classical retrieval augmented pipeline. Refer to the [RAG Haystack tutorial](https://haystack.deepset.ai/tutorials/27_first_rag_pipeline) for details.\n"
      ],
      "metadata": {
        "id": "18tOCjLEDNGu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack import Pipeline\n",
        "from haystack.components.builders import PromptBuilder\n",
        "from haystack.components.embedders import OpenAITextEmbedder\n",
        "from haystack.components.generators import OpenAIGenerator\n",
        "from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever\n",
        "\n",
        "text_embedder = OpenAITextEmbedder()\n",
        "retriever = InMemoryEmbeddingRetriever(document_store)\n",
        "generator = OpenAIGenerator(model=\"gpt-3.5-turbo\")\n",
        "\n",
        "template = \"\"\"\n",
        "Given the following information, answer the question.\n",
        "\n",
        "Context:\n",
        "{% for document in documents %}\n",
        "    {{ document.content }}\n",
        "{% endfor %}\n",
        "\n",
        "Question: {{question}}\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "prompt_builder = PromptBuilder(template=template)\n",
        "\n",
        "# Add components to your pipeline\n",
        "print(\"Initializing pipeline...\")\n",
        "pipe = Pipeline()\n",
        "pipe.add_component(\"embedder\", text_embedder)\n",
        "pipe.add_component(\"retriever\", retriever)\n",
        "pipe.add_component(\"prompt_builder\", prompt_builder)\n",
        "pipe.add_component(\"llm\", generator)\n",
        "\n",
        "# Now, connect the components to each other\n",
        "pipe.connect(\"embedder.embedding\", \"retriever.query_embedding\")\n",
        "pipe.connect(\"retriever\", \"prompt_builder.documents\")\n",
        "pipe.connect(\"prompt_builder\", \"llm\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31W_jlNWFkz3",
        "outputId": "af4ddf9a-3ea1-4d4a-bb08-bd2d828fe517"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing pipeline...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<haystack.core.pipeline.pipeline.Pipeline object at 0x7c02095efdc0>\n",
              "🚅 Components\n",
              "  - embedder: OpenAITextEmbedder\n",
              "  - retriever: InMemoryEmbeddingRetriever\n",
              "  - prompt_builder: PromptBuilder\n",
              "  - llm: OpenAIGenerator\n",
              "🛤️ Connections\n",
              "  - embedder.embedding -> retriever.query_embedding (List[float])\n",
              "  - retriever.documents -> prompt_builder.documents (List[Document])\n",
              "  - prompt_builder.prompt -> llm.prompt (str)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, you can ask questions about Haystack and get correct answers:"
      ],
      "metadata": {
        "id": "CXP-_TqcGU2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What is haystack?\"\n",
        "\n",
        "response = pipe.run({\"embedder\": {\"text\": question}, \"prompt_builder\": {\"question\": question}})\n",
        "\n",
        "print(f\"question: {question}\")\n",
        "print(f\"answer: {response['llm']['replies'][0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPtoRZEdF1BN",
        "outputId": "cb8d2266-6274-42b8-cf25-765c2d3de62f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "question: What is haystack?\n",
            "answer: Haystack is an open-source Python framework designed to help developers build LLM-powered custom applications. It is used for creating production-ready LLM applications, retrieval-augmented generative pipelines, and state-of-the-art search systems that work effectively over large document collections. Haystack offers comprehensive tooling for developing AI systems that use LLMs from platforms like Hugging Face, OpenAI, Cohere, Mistral, and more. It provides a modular and intuitive framework that allows users to quickly integrate the latest AI models, offering flexibility and ease of use. The framework includes components and pipelines that enable developers to build end-to-end AI projects without the need to understand the underlying models deeply. Haystack caters to LLM enthusiasts and beginners alike, providing a vibrant open-source community for collaboration and learning.\n"
          ]
        }
      ]
    }
  ]
}